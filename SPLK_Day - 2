Rex ----

|makeresults | eval credit_card_number="1234-5678-9101-1213" | rex field=credit_card_number max_match=0 "(?P<digits>\d{4})"

Masking

Replacement :-
|makeresults | eval credit_card_number="1234-5678-9101-1213" | rex field=credit_card_number mode=sed "s/(\d{4}-){3}/XXXX-XXXX-XXXX-/g"

Substitute:-

|makeresults | eval credit_card_number="1234-5678-9101-1213" | rex field=credit_card_number mode=sed "y/1234/XXXX/"

EREX

index=main sourcetype=txt | erex email examples="MariaDubois@example.com, lyra@buttercupgames.com"

Regex

index=main sourcetype=txt | regex _raw = "From:\s+<[[:alnum:]]+@[[:alnum:]]+\.[[:alpha:]]+>"

index=main sourcetype=txt |regex _raw = "From:\s+<[[:alnum:]]+\_[[:alnum:]]+@[[:alnum:]]+\.[[:alpha:]]+>"
====================================================================================================

XYSeries and untable command ----

index=main source="Sample_tickets.csv" | stats count by current_ticket_state, severity | xyseries current_ticket_state severity count

index=main source="Sample_tickets.csv" | stats count by current_ticket_state, severity | xyseries current_ticket_state severity count | untable current_ticket_state severity count

====================================================================================================

transaction ----

index=transact sourcetype=access_* | transaction JSESSIONID clientip startswith="view" endswith="purchase" | highlight "action"

maxpause - 

index=transact sourcetype=access_* | transaction action clientip JSESSIONID maxpause=3s | highlight "action"

maxspan - 

index=transact sourcetype=access_* | transaction action clientip JSESSIONID maxspan=4s | highlight "action" "POST /cart.do?action"

maxevent - 

index=transact sourcetype=access_* | transaction action clientip JSESSIONID maxspan=5s maxevents=4 | highlight "action" "POST /cart.do?action"

index=transact sourcetype=access_* | transaction clientip JSESSIONID maxevents=4

====================================================================================================

Predict :-

index=main source="power_usage_2016_to_2020.csv" | timechart span=1mon  avg("Value _kWh") as val | predict val algorithm=LL

index=main source="power_usage_2016_to_2020.csv" | timechart span=1mon  avg("Value _kWh") as val | predict val algorithm=LLP5 holdback=5

index=main source="power_usage_2016_to_2020.csv" | timechart span=1y  avg("Value _kWh") as val |  fillnull  | search val!=0

index=main source="power_usage_2016_to_2020.csv" | timechart span=1y  avg("Value _kWh") as val |  fillnull  | search val!=0 | predict val algorithm=LL

index=main source="weather_2016_2020_daily.csv" | table Temp_avg Dew_avg Date _time | eval date_epoc = strptime(Date, "%Y-%m-%d") | eval _time = date_epoc | timechart span=1mon avg(Temp_avg) as avg_temp, avg(Dew_avg) as avg_dew | predict avg_temp avg_dew algorithm=BiLL

index=main source="weather_2016_2020_daily.csv" | table Temp_avg, Dew_avg, Date, _time | eval date_epoc = strptime(Date, "%Y-%m-%d") | eval _time = date_epoc | timechart span=1mon avg(Temp_avg) as avg_temp, avg(Dew_avg) as avg_dew | predict avg_temp avg_dew algorithm=BiLL future_timespan=30

===================================================================================================
tstats

| tstats count where index=_internal sourcetype IN (splunkd, splunkd_ui_access) by sourcetype

| tstats count where index=_internal sourcetype IN (splunkd, splunkd_ui_access) by _time span=2d

====================================================================================================

append -

index=main source="Sample_tickets.csv" | stats count by severity | append[search index=main source="power_usage_2016_to_2020.csv" | stats avg("Value _kWh")]

appendcols - 

index=main source="Sample_tickets.csv" | stats count by severity | appendcols[search index=main source="power_usage_2016_to_2020.csv" | stats avg("Value _kWh")]

appendpipe -

index=main source="Sample_tickets.csv" | stats count by current_ticket_state, severity | appendpipe[|stats sum(count) as count by current_ticket_state | eval severity = "Sum By Ticket State"] | sort current_ticket_state

====================================================================================================

Join - 

Inner Join - 

index=main source="sample_tickets.csv" | table ticket_number, severity, current_ticket_state | join type="inner" ticket_number [search index=main_join | table ticket_number, time_taken]

Left Join - 

index=main source="sample_tickets.csv" | table ticket_number, severity, current_ticket_state | join type="left" ticket_number [search index=main_join | table ticket_number, time_taken]

index=main source="sample_tickets.csv" | table ticket_number, severity, current_ticket_state , time_taken | eval time_taken="NULL" | join overwrite=true type="left" ticket_number [search index=main_join | table ticket_number, time_taken]

Map - 

index=main source="sample_tickets.csv" | table ticket_number, severity, current_ticket_state | map maxsearches=100 search="search index=main_join ticket_number=$ticket_number$| table ticket_number, time_taken | eval severity=$severity$, ticket_state=$current_ticket_state$"

SELF - 

source="data_selfjoin.csv" host="ip-172-31-56-191.ec2.internal" index="main_self" sourcetype="csv" | table employee_id, manager_id, name, title | sort employee_id | selfjoin title

====================================================================================================

XMLKV 

| makeresults | eval data_xml = "
<games>
<game>
<name>Combat Games</name>
<category>competitive</category>
</game>
</games>"
| xmlkv data_xml

XPATH - 

index=main_xml | xpath outfield=country "//country/@name"

index=main_xml | xpath outfield=direction "//country/neighbor/@direction"

index=main_xml | xpath outfield=country "//country[@name='Singapore']/@name"